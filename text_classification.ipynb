{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Classification\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from transformers import DistilBertTokenizer, AutoModel"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A First Look at Hugging Face Datasets\n",
    "link: https://github.com/huggingface/datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No config specified, defaulting to: emotion/split\n",
      "Found cached dataset emotion (C:/Users/andsfonseca/.cache/huggingface/datasets/emotion/split/1.0.0/cca5efe2dfeb58c1d098e0f9eeb200e9927d889b5a03c67097275dfb5fe463bd)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb9cde92aa624857950b67a23d6742e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 16000\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 2000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 2000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the emotion dataset with the load_dataset() function:\n",
    "emotions = load_dataset(\"emotion\")\n",
    "emotions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'label'],\n",
       "    num_rows: 16000\n",
       "})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we can use the usual dictionary syntax to access an individual split:\n",
    "train_ds = emotions[\"train\"]\n",
    "train_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length:  16000\n",
      "Column names: ['text', 'label']\n",
      "Values:  {'text': Value(dtype='string', id=None), 'label': ClassLabel(names=['sadness', 'joy', 'love', 'anger', 'fear', 'surprise'], id=None)}\n",
      "Access a single example by its index: {'text': 'i didnt feel humiliated', 'label': 0}\n"
     ]
    }
   ],
   "source": [
    "print(\"Length: \", len(train_ds))\n",
    "print(\"Column names:\", train_ds.column_names)\n",
    "print(\"Values: \", train_ds.features)\n",
    "print(\"Access a single example by its index:\", train_ds[0])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### From Datasets to DataFrames\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "emotions.set_format(type=\"pandas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i didnt feel humiliated</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i can go from feeling so hopeless to so damned...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>im grabbing a minute to post i feel greedy wrong</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i am ever feeling nostalgic about the fireplac...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i am feeling grouchy</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0                            i didnt feel humiliated      0\n",
       "1  i can go from feeling so hopeless to so damned...      0\n",
       "2   im grabbing a minute to post i feel greedy wrong      3\n",
       "3  i am ever feeling nostalgic about the fireplac...      2\n",
       "4                               i am feeling grouchy      3"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = emotions[\"train\"][:]\n",
    "\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>label_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i didnt feel humiliated</td>\n",
       "      <td>0</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i can go from feeling so hopeless to so damned...</td>\n",
       "      <td>0</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>im grabbing a minute to post i feel greedy wrong</td>\n",
       "      <td>3</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i am ever feeling nostalgic about the fireplac...</td>\n",
       "      <td>2</td>\n",
       "      <td>love</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i am feeling grouchy</td>\n",
       "      <td>3</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label label_name\n",
       "0                            i didnt feel humiliated      0    sadness\n",
       "1  i can go from feeling so hopeless to so damned...      0    sadness\n",
       "2   im grabbing a minute to post i feel greedy wrong      3      anger\n",
       "3  i am ever feeling nostalgic about the fireplac...      2       love\n",
       "4                               i am feeling grouchy      3      anger"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def label_int2str(row):\n",
    "    return emotions[\"train\"].features[\"label\"].int2str(row)\n",
    "\n",
    "df_train[\"label_name\"] = df_train[\"label\"].apply(label_int2str)\n",
    "\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_train[\"label_name\"].value_counts(ascending=True).plot.barh(color={\"red\", \"green\", \"pink\", \"blue\", \"orange\", \"purple\"})\n",
    "plt.title(\"Frequency of Classes\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_train[\"Words Per Tweet\"] = df_train[\"text\"].str.split().apply(len)\n",
    "\n",
    "props = dict(boxes=\"Orange\", whiskers=\"Black\", medians=\"Black\", caps=\"Black\")\n",
    "boxplot = df_train.boxplot(\"Words Per Tweet\", by=\"label_name\", grid=False, showfliers=False, color=props, patch_artist=True)\n",
    "\n",
    "plt.suptitle(\"\")\n",
    "plt.xlabel(\"\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "emotions.reset_format()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From Text to Tokens\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Character Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'i remember feeling acutely distressed for a few days'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_text = df_train[\"text\"][31]\n",
    "example_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', ' ', 'r', 'e', 'm', 'e', 'm', 'b', 'e', 'r', ' ', 'f', 'e', 'e', 'l', 'i', 'n', 'g', ' ', 'a', 'c', 'u', 't', 'e', 'l', 'y', ' ', 'd', 'i', 's', 't', 'r', 'e', 's', 's', 'e', 'd', ' ', 'f', 'o', 'r', ' ', 'a', ' ', 'f', 'e', 'w', ' ', 'd', 'a', 'y', 's']\n"
     ]
    }
   ],
   "source": [
    "tokenized_example_text = list(example_text)\n",
    "print(tokenized_example_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{' ': 0, 'a': 1, 'b': 2, 'c': 3, 'd': 4, 'e': 5, 'f': 6, 'g': 7, 'i': 8, 'l': 9, 'm': 10, 'n': 11, 'o': 12, 'r': 13, 's': 14, 't': 15, 'u': 16, 'w': 17, 'y': 18}\n"
     ]
    }
   ],
   "source": [
    "token2id_example = {ch: idx for idx, ch in enumerate(sorted(set(tokenized_example_text)))}\n",
    "print(token2id_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8, 0, 13, 5, 10, 5, 10, 2, 5, 13, 0, 6, 5, 5, 9, 8, 11, 7, 0, 1, 3, 16, 15, 5, 9, 18, 0, 4, 8, 14, 15, 13, 5, 14, 14, 5, 4, 0, 6, 12, 13, 0, 1, 0, 6, 5, 17, 0, 4, 1, 18, 14]\n"
     ]
    }
   ],
   "source": [
    "tokenized_example_ids = [token2id_example[token] for token in tokenized_example_text]\n",
    "print(tokenized_example_ids)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none;background-color:gray;\"></hr>\n",
    "\n",
    "##### One-hot vectors\n",
    "\n",
    "Each token has now been mapped to a unique numerical identifier (hence the name input_ids). The last step is to convert input_ids to a 2D tensor of one-hot vectors. You can see a example in this notebook [One-hot Vectors](./2-text-classification/one_hot_vector.ipynb)\n",
    "\n",
    "<hr style=\"height:2px;border:none;background-color:gray;\"></hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([52, 19])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ids = torch.tensor(tokenized_example_ids)\n",
    "one_hot_encodings = F.one_hot(input_ids, num_classes=len(token2id_example))\n",
    "one_hot_encodings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token: i\n",
      "Tensor index: 8\n",
      "One-hot: tensor([0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n"
     ]
    }
   ],
   "source": [
    "print(f\"Token: {tokenized_example_text[0]}\")\n",
    "print(f\"Tensor index: {tokenized_example_ids[0]}\")\n",
    "print(f\"One-hot: {one_hot_encodings[0]}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Word Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " 'remember',\n",
       " 'feeling',\n",
       " 'acutely',\n",
       " 'distressed',\n",
       " 'for',\n",
       " 'a',\n",
       " 'few',\n",
       " 'days']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_word_example_text = example_text.split()\n",
    "tokenized_word_example_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'a': 0, 'acutely': 1, 'days': 2, 'distressed': 3, 'feeling': 4, 'few': 5, 'for': 6, 'i': 7, 'remember': 8}\n"
     ]
    }
   ],
   "source": [
    "token2id_word_example = {ch: idx for idx, ch in enumerate(sorted(set(tokenized_word_example_text)))}\n",
    "print(token2id_word_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7, 8, 4, 1, 3, 6, 0, 5, 2]\n"
     ]
    }
   ],
   "source": [
    "tokenized_word_example_ids = [token2id_word_example[token] for token in tokenized_word_example_text]\n",
    "print(tokenized_word_example_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token: feeling\n",
      "Tensor index: 4\n",
      "One-hot: tensor([0, 0, 0, 0, 1, 0, 0, 0, 0])\n"
     ]
    }
   ],
   "source": [
    "input_ids = torch.tensor(tokenized_word_example_ids)\n",
    "one_hot_encodings = F.one_hot(input_ids, num_classes=len(token2id_word_example))\n",
    "print(f\"Token: {tokenized_word_example_text[2]}\")\n",
    "print(f\"Tensor index: {tokenized_word_example_ids[2]}\")\n",
    "print(f\"One-hot: {one_hot_encodings[2]}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Subword Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ckpt = \"distilbert-base-uncased\"\n",
    "distilbert_tokenizer = DistilBertTokenizer.from_pretrained(model_ckpt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i remember feeling acutely distressed for a few days\n",
      "[101, 1045, 3342, 3110, 11325, 2135, 24305, 2005, 1037, 2261, 2420, 102]\n"
     ]
    }
   ],
   "source": [
    "# gerando os tokens usando Distilbert Tokenizer\n",
    "encoded_text = distilbert_tokenizer(example_text)\n",
    "\n",
    "print(example_text)\n",
    "print(encoded_text[\"input_ids\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[CLS]',\n",
       " 'i',\n",
       " 'remember',\n",
       " 'feeling',\n",
       " 'acute',\n",
       " '##ly',\n",
       " 'distressed',\n",
       " 'for',\n",
       " 'a',\n",
       " 'few',\n",
       " 'days',\n",
       " '[SEP]']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# vendo os tokens\n",
    "tokens = distilbert_tokenizer.convert_ids_to_tokens(encoded_text.input_ids)\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[CLS] i remember feeling acutely distressed for a few days [SEP]'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convertendo os tokens para texto\n",
    "distilbert_tokenizer.convert_tokens_to_string(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30522"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tamanho do vocabulrio\n",
    "distilbert_tokenizer.vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "512"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tamanho mximo do contexto\n",
    "distilbert_tokenizer.model_max_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['input_ids', 'attention_mask']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# nomes dos campos que o modelo espera\n",
    "distilbert_tokenizer.model_input_names"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenizing the Whole Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(batch):\n",
    "    return distilbert_tokenizer(batch[\"text\"], padding=True, truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[101, 1045, 2134, 2102, 2514, 26608, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [101, 1045, 2064, 2175, 2013, 3110, 2061, 20625, 2000, 2061, 9636, 17772, 2074, 2013, 2108, 2105, 2619, 2040, 14977, 1998, 2003, 8300, 102]]\n"
     ]
    }
   ],
   "source": [
    "print(tokenize(emotions[\"train\"][:2])[\"input_ids\"])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|   Special Token  | [PAD] | [UNK] | [CLS] | [SEP] | [MASK] |\n",
    "|:----------------:|:-----:|:-----:|:-----:|:-----:|:------:|\n",
    "| Special Token ID |   0   |  100  |  101  |  102  |   103  |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[CLS]',\n",
       " 'i',\n",
       " 'didn',\n",
       " '##t',\n",
       " 'feel',\n",
       " 'humiliated',\n",
       " '[SEP]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = distilbert_tokenizer.convert_ids_to_tokens(tokenize(emotions[\"train\"][:2])[\"input_ids\"][0])\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at C:\\Users\\andsfonseca\\.cache\\huggingface\\datasets\\emotion\\split\\1.0.0\\cca5efe2dfeb58c1d098e0f9eeb200e9927d889b5a03c67097275dfb5fe463bd\\cache-553164a32a56ed0d.arrow\n",
      "Loading cached processed dataset at C:\\Users\\andsfonseca\\.cache\\huggingface\\datasets\\emotion\\split\\1.0.0\\cca5efe2dfeb58c1d098e0f9eeb200e9927d889b5a03c67097275dfb5fe463bd\\cache-05ba5a25c9e0c839.arrow\n",
      "Loading cached processed dataset at C:\\Users\\andsfonseca\\.cache\\huggingface\\datasets\\emotion\\split\\1.0.0\\cca5efe2dfeb58c1d098e0f9eeb200e9927d889b5a03c67097275dfb5fe463bd\\cache-ad50915c1d83e5dc.arrow\n"
     ]
    }
   ],
   "source": [
    "# aplicando em todo o dataset a funo tokenizadora\n",
    "emotions_encoded = emotions.map(tokenize, batched=True, batch_size=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i didnt feel humiliated\n",
      "[101, 1045, 2134, 2102, 2514, 26608, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "for i in range(1):\n",
    "    row = emotions_encoded[\"train\"][i]  \n",
    "    print(row[\"text\"]) \n",
    "    print(row[\"input_ids\"]) \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training a Text Classifier\n",
    "\n",
    "* Feature Extraction\n",
    "* Fine-tuning\n",
    "\n",
    "### Transformers as Feature Extractor\n",
    "\n",
    "#### Using pretrained models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_transform.bias', 'vocab_transform.weight', 'vocab_layer_norm.weight', 'vocab_projector.weight', 'vocab_projector.bias', 'vocab_layer_norm.bias']\n",
      "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "model_ckpt = \"distilbert-base-uncased\"\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = AutoModel.from_pretrained(model_ckpt).to(device)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extracting the last hidden states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'i remember feeling acutely distressed for a few days'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input tensor shape: torch.Size([1, 12])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "inputs = distilbert_tokenizer(example_text, return_tensors=\"pt\")\n",
    "print(f\"Input tensor shape: {inputs['input_ids'].size()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BaseModelOutput(last_hidden_state=tensor([[[ 0.0267,  0.0243, -0.1351,  ...,  0.0231,  0.1226,  0.2348],\n",
      "         [ 0.3981,  0.1839, -0.3101,  ...,  0.1541,  0.6333,  0.0120],\n",
      "         [-0.0371,  0.1825, -0.0489,  ...,  0.0914, -0.3788, -0.2676],\n",
      "         ...,\n",
      "         [-0.2624, -0.3020,  0.2109,  ..., -0.3921, -0.6568, -0.0390],\n",
      "         [-0.2264, -0.1025, -0.0399,  ..., -0.1844, -0.3466, -0.4665],\n",
      "         [ 0.9699,  0.1726, -0.3798,  ...,  0.2346, -0.4845, -0.4161]]],\n",
      "       device='cuda:0'), hidden_states=None, attentions=None)\n"
     ]
    }
   ],
   "source": [
    "inputs = {k:v.to(device) for k,v in inputs.items()}\n",
    "with torch.no_grad():\n",
    " outputs = model(**inputs)\n",
    "print(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 12, 768])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs.last_hidden_state.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 768])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs.last_hidden_state[:,0].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_hidden_states(batch):\n",
    "    # Place model inputs on the GPU\n",
    "    inputs = {k:v.to(device) for k,v in batch.items() if k in distilbert_tokenizer.model_input_names}\n",
    "    # Extract last hidden states\n",
    "    with torch.no_grad():\n",
    "        last_hidden_state = model(**inputs).last_hidden_state\n",
    "        \n",
    "    # Return vector for [CLS] token\n",
    "    return {\"hidden_state\": last_hidden_state[:,0].cpu().numpy()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "emotions_encoded.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "258cab2665c94ba89784e861ffe60c8e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/16000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 1020.00 MiB (GPU 0; 4.00 GiB total capacity; 2.00 GiB already allocated; 206.19 MiB free; 2.53 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[41], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m torch\u001b[39m.\u001b[39mcuda\u001b[39m.\u001b[39mempty_cache()\n\u001b[1;32m----> 2\u001b[0m emotions_hidden \u001b[39m=\u001b[39m emotions_encoded\u001b[39m.\u001b[39;49mmap(extract_hidden_states, batched\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "File \u001b[1;32md:\\Documents\\Workspaces\\Python\\nlp-with-transformers\\.venv\\Lib\\site-packages\\datasets\\dataset_dict.py:851\u001b[0m, in \u001b[0;36mDatasetDict.map\u001b[1;34m(self, function, with_indices, with_rank, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, load_from_cache_file, cache_file_names, writer_batch_size, features, disable_nullable, fn_kwargs, num_proc, desc)\u001b[0m\n\u001b[0;32m    848\u001b[0m \u001b[39mif\u001b[39;00m cache_file_names \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    849\u001b[0m     cache_file_names \u001b[39m=\u001b[39m {k: \u001b[39mNone\u001b[39;00m \u001b[39mfor\u001b[39;00m k \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m}\n\u001b[0;32m    850\u001b[0m \u001b[39mreturn\u001b[39;00m DatasetDict(\n\u001b[1;32m--> 851\u001b[0m     {\n\u001b[0;32m    852\u001b[0m         k: dataset\u001b[39m.\u001b[39;49mmap(\n\u001b[0;32m    853\u001b[0m             function\u001b[39m=\u001b[39;49mfunction,\n\u001b[0;32m    854\u001b[0m             with_indices\u001b[39m=\u001b[39;49mwith_indices,\n\u001b[0;32m    855\u001b[0m             with_rank\u001b[39m=\u001b[39;49mwith_rank,\n\u001b[0;32m    856\u001b[0m             input_columns\u001b[39m=\u001b[39;49minput_columns,\n\u001b[0;32m    857\u001b[0m             batched\u001b[39m=\u001b[39;49mbatched,\n\u001b[0;32m    858\u001b[0m             batch_size\u001b[39m=\u001b[39;49mbatch_size,\n\u001b[0;32m    859\u001b[0m             drop_last_batch\u001b[39m=\u001b[39;49mdrop_last_batch,\n\u001b[0;32m    860\u001b[0m             remove_columns\u001b[39m=\u001b[39;49mremove_columns,\n\u001b[0;32m    861\u001b[0m             keep_in_memory\u001b[39m=\u001b[39;49mkeep_in_memory,\n\u001b[0;32m    862\u001b[0m             load_from_cache_file\u001b[39m=\u001b[39;49mload_from_cache_file,\n\u001b[0;32m    863\u001b[0m             cache_file_name\u001b[39m=\u001b[39;49mcache_file_names[k],\n\u001b[0;32m    864\u001b[0m             writer_batch_size\u001b[39m=\u001b[39;49mwriter_batch_size,\n\u001b[0;32m    865\u001b[0m             features\u001b[39m=\u001b[39;49mfeatures,\n\u001b[0;32m    866\u001b[0m             disable_nullable\u001b[39m=\u001b[39;49mdisable_nullable,\n\u001b[0;32m    867\u001b[0m             fn_kwargs\u001b[39m=\u001b[39;49mfn_kwargs,\n\u001b[0;32m    868\u001b[0m             num_proc\u001b[39m=\u001b[39;49mnum_proc,\n\u001b[0;32m    869\u001b[0m             desc\u001b[39m=\u001b[39;49mdesc,\n\u001b[0;32m    870\u001b[0m         )\n\u001b[0;32m    871\u001b[0m         \u001b[39mfor\u001b[39;49;00m k, dataset \u001b[39min\u001b[39;49;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mitems()\n\u001b[0;32m    872\u001b[0m     }\n\u001b[0;32m    873\u001b[0m )\n",
      "File \u001b[1;32md:\\Documents\\Workspaces\\Python\\nlp-with-transformers\\.venv\\Lib\\site-packages\\datasets\\dataset_dict.py:852\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    848\u001b[0m \u001b[39mif\u001b[39;00m cache_file_names \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    849\u001b[0m     cache_file_names \u001b[39m=\u001b[39m {k: \u001b[39mNone\u001b[39;00m \u001b[39mfor\u001b[39;00m k \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m}\n\u001b[0;32m    850\u001b[0m \u001b[39mreturn\u001b[39;00m DatasetDict(\n\u001b[0;32m    851\u001b[0m     {\n\u001b[1;32m--> 852\u001b[0m         k: dataset\u001b[39m.\u001b[39;49mmap(\n\u001b[0;32m    853\u001b[0m             function\u001b[39m=\u001b[39;49mfunction,\n\u001b[0;32m    854\u001b[0m             with_indices\u001b[39m=\u001b[39;49mwith_indices,\n\u001b[0;32m    855\u001b[0m             with_rank\u001b[39m=\u001b[39;49mwith_rank,\n\u001b[0;32m    856\u001b[0m             input_columns\u001b[39m=\u001b[39;49minput_columns,\n\u001b[0;32m    857\u001b[0m             batched\u001b[39m=\u001b[39;49mbatched,\n\u001b[0;32m    858\u001b[0m             batch_size\u001b[39m=\u001b[39;49mbatch_size,\n\u001b[0;32m    859\u001b[0m             drop_last_batch\u001b[39m=\u001b[39;49mdrop_last_batch,\n\u001b[0;32m    860\u001b[0m             remove_columns\u001b[39m=\u001b[39;49mremove_columns,\n\u001b[0;32m    861\u001b[0m             keep_in_memory\u001b[39m=\u001b[39;49mkeep_in_memory,\n\u001b[0;32m    862\u001b[0m             load_from_cache_file\u001b[39m=\u001b[39;49mload_from_cache_file,\n\u001b[0;32m    863\u001b[0m             cache_file_name\u001b[39m=\u001b[39;49mcache_file_names[k],\n\u001b[0;32m    864\u001b[0m             writer_batch_size\u001b[39m=\u001b[39;49mwriter_batch_size,\n\u001b[0;32m    865\u001b[0m             features\u001b[39m=\u001b[39;49mfeatures,\n\u001b[0;32m    866\u001b[0m             disable_nullable\u001b[39m=\u001b[39;49mdisable_nullable,\n\u001b[0;32m    867\u001b[0m             fn_kwargs\u001b[39m=\u001b[39;49mfn_kwargs,\n\u001b[0;32m    868\u001b[0m             num_proc\u001b[39m=\u001b[39;49mnum_proc,\n\u001b[0;32m    869\u001b[0m             desc\u001b[39m=\u001b[39;49mdesc,\n\u001b[0;32m    870\u001b[0m         )\n\u001b[0;32m    871\u001b[0m         \u001b[39mfor\u001b[39;00m k, dataset \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems()\n\u001b[0;32m    872\u001b[0m     }\n\u001b[0;32m    873\u001b[0m )\n",
      "File \u001b[1;32md:\\Documents\\Workspaces\\Python\\nlp-with-transformers\\.venv\\Lib\\site-packages\\datasets\\arrow_dataset.py:563\u001b[0m, in \u001b[0;36mtransmit_tasks.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    561\u001b[0m     \u001b[39mself\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39mDataset\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m=\u001b[39m kwargs\u001b[39m.\u001b[39mpop(\u001b[39m\"\u001b[39m\u001b[39mself\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    562\u001b[0m \u001b[39m# apply actual function\u001b[39;00m\n\u001b[1;32m--> 563\u001b[0m out: Union[\u001b[39m\"\u001b[39m\u001b[39mDataset\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mDatasetDict\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m func(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    564\u001b[0m datasets: List[\u001b[39m\"\u001b[39m\u001b[39mDataset\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(out\u001b[39m.\u001b[39mvalues()) \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(out, \u001b[39mdict\u001b[39m) \u001b[39melse\u001b[39;00m [out]\n\u001b[0;32m    565\u001b[0m \u001b[39mfor\u001b[39;00m dataset \u001b[39min\u001b[39;00m datasets:\n\u001b[0;32m    566\u001b[0m     \u001b[39m# Remove task templates if a column mapping of the template is no longer valid\u001b[39;00m\n",
      "File \u001b[1;32md:\\Documents\\Workspaces\\Python\\nlp-with-transformers\\.venv\\Lib\\site-packages\\datasets\\arrow_dataset.py:528\u001b[0m, in \u001b[0;36mtransmit_format.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    521\u001b[0m self_format \u001b[39m=\u001b[39m {\n\u001b[0;32m    522\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtype\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_format_type,\n\u001b[0;32m    523\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mformat_kwargs\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_format_kwargs,\n\u001b[0;32m    524\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mcolumns\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_format_columns,\n\u001b[0;32m    525\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39moutput_all_columns\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_output_all_columns,\n\u001b[0;32m    526\u001b[0m }\n\u001b[0;32m    527\u001b[0m \u001b[39m# apply actual function\u001b[39;00m\n\u001b[1;32m--> 528\u001b[0m out: Union[\u001b[39m\"\u001b[39m\u001b[39mDataset\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mDatasetDict\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m func(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    529\u001b[0m datasets: List[\u001b[39m\"\u001b[39m\u001b[39mDataset\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(out\u001b[39m.\u001b[39mvalues()) \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(out, \u001b[39mdict\u001b[39m) \u001b[39melse\u001b[39;00m [out]\n\u001b[0;32m    530\u001b[0m \u001b[39m# re-apply format to the output\u001b[39;00m\n",
      "File \u001b[1;32md:\\Documents\\Workspaces\\Python\\nlp-with-transformers\\.venv\\Lib\\site-packages\\datasets\\arrow_dataset.py:3004\u001b[0m, in \u001b[0;36mDataset.map\u001b[1;34m(self, function, with_indices, with_rank, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, load_from_cache_file, cache_file_name, writer_batch_size, features, disable_nullable, fn_kwargs, num_proc, suffix_template, new_fingerprint, desc)\u001b[0m\n\u001b[0;32m   2996\u001b[0m \u001b[39mif\u001b[39;00m transformed_dataset \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   2997\u001b[0m     \u001b[39mwith\u001b[39;00m logging\u001b[39m.\u001b[39mtqdm(\n\u001b[0;32m   2998\u001b[0m         disable\u001b[39m=\u001b[39m\u001b[39mnot\u001b[39;00m logging\u001b[39m.\u001b[39mis_progress_bar_enabled(),\n\u001b[0;32m   2999\u001b[0m         unit\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m examples\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3002\u001b[0m         desc\u001b[39m=\u001b[39mdesc \u001b[39mor\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mMap\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   3003\u001b[0m     ) \u001b[39mas\u001b[39;00m pbar:\n\u001b[1;32m-> 3004\u001b[0m         \u001b[39mfor\u001b[39;00m rank, done, content \u001b[39min\u001b[39;00m Dataset\u001b[39m.\u001b[39m_map_single(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mdataset_kwargs):\n\u001b[0;32m   3005\u001b[0m             \u001b[39mif\u001b[39;00m done:\n\u001b[0;32m   3006\u001b[0m                 shards_done \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "File \u001b[1;32md:\\Documents\\Workspaces\\Python\\nlp-with-transformers\\.venv\\Lib\\site-packages\\datasets\\arrow_dataset.py:3380\u001b[0m, in \u001b[0;36mDataset._map_single\u001b[1;34m(shard, function, with_indices, with_rank, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, cache_file_name, writer_batch_size, features, disable_nullable, fn_kwargs, new_fingerprint, rank, offset)\u001b[0m\n\u001b[0;32m   3376\u001b[0m indices \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(\n\u001b[0;32m   3377\u001b[0m     \u001b[39mrange\u001b[39m(\u001b[39m*\u001b[39m(\u001b[39mslice\u001b[39m(i, i \u001b[39m+\u001b[39m batch_size)\u001b[39m.\u001b[39mindices(shard\u001b[39m.\u001b[39mnum_rows)))\n\u001b[0;32m   3378\u001b[0m )  \u001b[39m# Something simpler?\u001b[39;00m\n\u001b[0;32m   3379\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 3380\u001b[0m     batch \u001b[39m=\u001b[39m apply_function_on_filtered_inputs(\n\u001b[0;32m   3381\u001b[0m         batch,\n\u001b[0;32m   3382\u001b[0m         indices,\n\u001b[0;32m   3383\u001b[0m         check_same_num_examples\u001b[39m=\u001b[39;49m\u001b[39mlen\u001b[39;49m(shard\u001b[39m.\u001b[39;49mlist_indexes()) \u001b[39m>\u001b[39;49m \u001b[39m0\u001b[39;49m,\n\u001b[0;32m   3384\u001b[0m         offset\u001b[39m=\u001b[39;49moffset,\n\u001b[0;32m   3385\u001b[0m     )\n\u001b[0;32m   3386\u001b[0m \u001b[39mexcept\u001b[39;00m NumExamplesMismatchError:\n\u001b[0;32m   3387\u001b[0m     \u001b[39mraise\u001b[39;00m DatasetTransformationNotAllowedError(\n\u001b[0;32m   3388\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mUsing `.map` in batched mode on a dataset with attached indexes is allowed only if it doesn\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt create or remove existing examples. You can first run `.drop_index() to remove your index and then re-add it.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   3389\u001b[0m     ) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n",
      "File \u001b[1;32md:\\Documents\\Workspaces\\Python\\nlp-with-transformers\\.venv\\Lib\\site-packages\\datasets\\arrow_dataset.py:3261\u001b[0m, in \u001b[0;36mDataset._map_single.<locals>.apply_function_on_filtered_inputs\u001b[1;34m(pa_inputs, indices, check_same_num_examples, offset)\u001b[0m\n\u001b[0;32m   3259\u001b[0m \u001b[39mif\u001b[39;00m with_rank:\n\u001b[0;32m   3260\u001b[0m     additional_args \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m (rank,)\n\u001b[1;32m-> 3261\u001b[0m processed_inputs \u001b[39m=\u001b[39m function(\u001b[39m*\u001b[39;49mfn_args, \u001b[39m*\u001b[39;49madditional_args, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfn_kwargs)\n\u001b[0;32m   3262\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(processed_inputs, LazyDict):\n\u001b[0;32m   3263\u001b[0m     processed_inputs \u001b[39m=\u001b[39m {\n\u001b[0;32m   3264\u001b[0m         k: v \u001b[39mfor\u001b[39;00m k, v \u001b[39min\u001b[39;00m processed_inputs\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mitems() \u001b[39mif\u001b[39;00m k \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m processed_inputs\u001b[39m.\u001b[39mkeys_to_format\n\u001b[0;32m   3265\u001b[0m     }\n",
      "Cell \u001b[1;32mIn[39], line 6\u001b[0m, in \u001b[0;36mextract_hidden_states\u001b[1;34m(batch)\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[39m# Extract last hidden states\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[1;32m----> 6\u001b[0m     last_hidden_state \u001b[39m=\u001b[39m model(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49minputs)\u001b[39m.\u001b[39mlast_hidden_state\n\u001b[0;32m      8\u001b[0m \u001b[39m# Return vector for [CLS] token\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[39mreturn\u001b[39;00m {\u001b[39m\"\u001b[39m\u001b[39mhidden_state\u001b[39m\u001b[39m\"\u001b[39m: last_hidden_state[:,\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mcpu()\u001b[39m.\u001b[39mnumpy()}\n",
      "File \u001b[1;32md:\\Documents\\Workspaces\\Python\\nlp-with-transformers\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32md:\\Documents\\Workspaces\\Python\\nlp-with-transformers\\.venv\\Lib\\site-packages\\transformers\\models\\distilbert\\modeling_distilbert.py:583\u001b[0m, in \u001b[0;36mDistilBertModel.forward\u001b[1;34m(self, input_ids, attention_mask, head_mask, inputs_embeds, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m    579\u001b[0m head_mask \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_head_mask(head_mask, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mnum_hidden_layers)\n\u001b[0;32m    581\u001b[0m embeddings \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39membeddings(input_ids, inputs_embeds)  \u001b[39m# (bs, seq_length, dim)\u001b[39;00m\n\u001b[1;32m--> 583\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtransformer(\n\u001b[0;32m    584\u001b[0m     x\u001b[39m=\u001b[39;49membeddings,\n\u001b[0;32m    585\u001b[0m     attn_mask\u001b[39m=\u001b[39;49mattention_mask,\n\u001b[0;32m    586\u001b[0m     head_mask\u001b[39m=\u001b[39;49mhead_mask,\n\u001b[0;32m    587\u001b[0m     output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[0;32m    588\u001b[0m     output_hidden_states\u001b[39m=\u001b[39;49moutput_hidden_states,\n\u001b[0;32m    589\u001b[0m     return_dict\u001b[39m=\u001b[39;49mreturn_dict,\n\u001b[0;32m    590\u001b[0m )\n",
      "File \u001b[1;32md:\\Documents\\Workspaces\\Python\\nlp-with-transformers\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32md:\\Documents\\Workspaces\\Python\\nlp-with-transformers\\.venv\\Lib\\site-packages\\transformers\\models\\distilbert\\modeling_distilbert.py:359\u001b[0m, in \u001b[0;36mTransformer.forward\u001b[1;34m(self, x, attn_mask, head_mask, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m    356\u001b[0m \u001b[39mif\u001b[39;00m output_hidden_states:\n\u001b[0;32m    357\u001b[0m     all_hidden_states \u001b[39m=\u001b[39m all_hidden_states \u001b[39m+\u001b[39m (hidden_state,)\n\u001b[1;32m--> 359\u001b[0m layer_outputs \u001b[39m=\u001b[39m layer_module(\n\u001b[0;32m    360\u001b[0m     x\u001b[39m=\u001b[39;49mhidden_state, attn_mask\u001b[39m=\u001b[39;49mattn_mask, head_mask\u001b[39m=\u001b[39;49mhead_mask[i], output_attentions\u001b[39m=\u001b[39;49moutput_attentions\n\u001b[0;32m    361\u001b[0m )\n\u001b[0;32m    362\u001b[0m hidden_state \u001b[39m=\u001b[39m layer_outputs[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\n\u001b[0;32m    364\u001b[0m \u001b[39mif\u001b[39;00m output_attentions:\n",
      "File \u001b[1;32md:\\Documents\\Workspaces\\Python\\nlp-with-transformers\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32md:\\Documents\\Workspaces\\Python\\nlp-with-transformers\\.venv\\Lib\\site-packages\\transformers\\models\\distilbert\\modeling_distilbert.py:313\u001b[0m, in \u001b[0;36mTransformerBlock.forward\u001b[1;34m(self, x, attn_mask, head_mask, output_attentions)\u001b[0m\n\u001b[0;32m    310\u001b[0m sa_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msa_layer_norm(sa_output \u001b[39m+\u001b[39m x)  \u001b[39m# (bs, seq_length, dim)\u001b[39;00m\n\u001b[0;32m    312\u001b[0m \u001b[39m# Feed Forward Network\u001b[39;00m\n\u001b[1;32m--> 313\u001b[0m ffn_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mffn(sa_output)  \u001b[39m# (bs, seq_length, dim)\u001b[39;00m\n\u001b[0;32m    314\u001b[0m ffn_output: torch\u001b[39m.\u001b[39mTensor \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moutput_layer_norm(ffn_output \u001b[39m+\u001b[39m sa_output)  \u001b[39m# (bs, seq_length, dim)\u001b[39;00m\n\u001b[0;32m    316\u001b[0m output \u001b[39m=\u001b[39m (ffn_output,)\n",
      "File \u001b[1;32md:\\Documents\\Workspaces\\Python\\nlp-with-transformers\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32md:\\Documents\\Workspaces\\Python\\nlp-with-transformers\\.venv\\Lib\\site-packages\\transformers\\models\\distilbert\\modeling_distilbert.py:254\u001b[0m, in \u001b[0;36mFFN.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    253\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: torch\u001b[39m.\u001b[39mTensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m torch\u001b[39m.\u001b[39mTensor:\n\u001b[1;32m--> 254\u001b[0m     \u001b[39mreturn\u001b[39;00m apply_chunking_to_forward(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mff_chunk, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mchunk_size_feed_forward, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mseq_len_dim, \u001b[39minput\u001b[39;49m)\n",
      "File \u001b[1;32md:\\Documents\\Workspaces\\Python\\nlp-with-transformers\\.venv\\Lib\\site-packages\\transformers\\pytorch_utils.py:248\u001b[0m, in \u001b[0;36mapply_chunking_to_forward\u001b[1;34m(forward_fn, chunk_size, chunk_dim, *input_tensors)\u001b[0m\n\u001b[0;32m    245\u001b[0m     \u001b[39m# concatenate output at same dimension\u001b[39;00m\n\u001b[0;32m    246\u001b[0m     \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39mcat(output_chunks, dim\u001b[39m=\u001b[39mchunk_dim)\n\u001b[1;32m--> 248\u001b[0m \u001b[39mreturn\u001b[39;00m forward_fn(\u001b[39m*\u001b[39;49minput_tensors)\n",
      "File \u001b[1;32md:\\Documents\\Workspaces\\Python\\nlp-with-transformers\\.venv\\Lib\\site-packages\\transformers\\models\\distilbert\\modeling_distilbert.py:258\u001b[0m, in \u001b[0;36mFFN.ff_chunk\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    256\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mff_chunk\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: torch\u001b[39m.\u001b[39mTensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m torch\u001b[39m.\u001b[39mTensor:\n\u001b[0;32m    257\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlin1(\u001b[39minput\u001b[39m)\n\u001b[1;32m--> 258\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mactivation(x)\n\u001b[0;32m    259\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlin2(x)\n\u001b[0;32m    260\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropout(x)\n",
      "File \u001b[1;32md:\\Documents\\Workspaces\\Python\\nlp-with-transformers\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32md:\\Documents\\Workspaces\\Python\\nlp-with-transformers\\.venv\\Lib\\site-packages\\transformers\\activations.py:78\u001b[0m, in \u001b[0;36mGELUActivation.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m     77\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m---> 78\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mact(\u001b[39minput\u001b[39;49m)\n",
      "\u001b[1;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 1020.00 MiB (GPU 0; 4.00 GiB total capacity; 2.00 GiB already allocated; 206.19 MiB free; 2.53 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "emotions_hidden = emotions_encoded.map(extract_hidden_states, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "fcd5e99b3f4d209fb77e3753520e7bb18e2dbb8cf950aa58c2b06da10909cacd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
